---
phase: 02-shared-library
plan: "01"
type: execute
wave: 1
depends_on: []
files_modified:
  - lib/logger.mjs
  - lib/json-extractor.mjs
  - lib/retry.mjs
  - lib/agent-resolver.mjs
autonomous: true
requirements: [ARCH-01, ARCH-03, ARCH-06]

must_haves:
  truths:
    - "extractJsonField() returns the value of a named field from valid hook JSON"
    - "extractJsonField() returns null and logs a JSONL warning for invalid JSON input"
    - "extractJsonField() returns null and logs a JSONL warning for a missing field"
    - "resolveAgentFromSession() reads agent-registry.json and returns the matching agent config for a known tmux session name"
    - "resolveAgentFromSession() returns null for an unrecognized session name (no error, no log)"
    - "resolveAgentFromSession() returns null for a disabled agent"
    - "retryWithBackoff() retries a failing async function with exponential backoff starting at 5s"
    - "retryWithBackoff() logs each retry attempt as N/M to JSONL"
    - "JSONL logger writes atomic entries to the same log file as hook-event-logger.sh"
  artifacts:
    - path: "lib/logger.mjs"
      provides: "Atomic JSONL logging with flock for concurrent hook safety"
      exports: ["appendJsonlEntry"]
    - path: "lib/json-extractor.mjs"
      provides: "Safe JSON field extraction with null fallback"
      exports: ["extractJsonField"]
    - path: "lib/retry.mjs"
      provides: "Exponential backoff retry wrapper for any async function"
      exports: ["retryWithBackoff"]
    - path: "lib/agent-resolver.mjs"
      provides: "Session-to-agent lookup via agent-registry.json"
      exports: ["resolveAgentFromSession"]
  key_links:
    - from: "lib/json-extractor.mjs"
      to: "lib/logger.mjs"
      via: "import appendJsonlEntry for warning logging"
      pattern: "import.*logger"
    - from: "lib/retry.mjs"
      to: "lib/logger.mjs"
      via: "import appendJsonlEntry for retry progress logging"
      pattern: "import.*logger"
    - from: "lib/agent-resolver.mjs"
      to: "config/agent-registry.json"
      via: "readFileSync to load registry"
      pattern: "readFileSync.*agent-registry"
---

<objective>
Build the four foundational lib modules: JSONL logger, JSON field extractor, retry utility, and agent resolver. These are the building blocks that the gateway module (Plan 02) and all future event handlers depend on.

Purpose: Establish the shared library foundation so event handlers never duplicate agent resolution, JSON parsing, retry logic, or structured logging.
Output: Four importable ESM modules in lib/ with zero external dependencies.
</objective>

<execution_context>
@/home/forge/.claude/get-shit-done/workflows/execute-plan.md
@/home/forge/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-shared-library/02-CONTEXT.md
@bin/hook-event-logger.sh
@bin/launch-session.mjs
@config/agent-registry.example.json
@config/SCHEMA.md
@package.json
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create JSONL logger and JSON field extractor</name>
  <files>lib/logger.mjs, lib/json-extractor.mjs</files>
  <action>
**lib/logger.mjs** — Atomic JSONL logging module.

Create a single exported function `appendJsonlEntry(logEntry)` that:
1. Resolves SKILL_ROOT using `import.meta.url` + `dirname(fileURLToPath())` (two levels up from lib/)
2. Resolves the log directory as `${SKILL_ROOT}/logs`
3. Creates the log directory with `mkdirSync(logDirectory, { recursive: true })` if it does not exist
4. Accepts a `logEntry` object with arbitrary fields
5. Captures `new Date().toISOString()` ONCE and assigns to `const entryTimestamp` — reuse this value, never call Date again in the same invocation (Phase 01.1 lesson: no redundant timestamp calls)
6. Builds a JSONL record: `{ timestamp: entryTimestamp, ...logEntry }`
7. Serializes with `JSON.stringify(record) + '\n'`
8. Writes atomically using `node:fs writeFileSync` with the `{ flag: 'a' }` append flag
9. For concurrent safety, use a lock file approach matching hook-event-logger.sh: open a `.lock` file with `openSync(lockFilePath, 'w')`, call a flock equivalent. Since Node.js has no native flock, use `execFileSync('flock', ['-x', lockFileDescriptor.toString()])` is NOT viable on file descriptors. Instead, implement atomic append by opening the target file with `O_APPEND | O_CREAT | O_WRONLY` flags via `openSync` and writing with `writeSync` then `closeSync`. The `O_APPEND` flag guarantees atomic appends on Linux for writes under PIPE_BUF (4096 bytes). This matches the safety guarantee of flock for small JSONL records.
10. The log file name should be derived from a `sessionName` parameter: `${sessionName}-raw-events.jsonl` — matching the existing convention from hook-event-logger.sh. If no sessionName is provided, use `lib-events.jsonl` as default.
11. All errors in the logger must be swallowed (try/catch with empty catch) — the logger must never crash the caller. This matches hook-event-logger.sh's `|| true` pattern.

Function signature: `appendJsonlEntry(logEntry, sessionName = null)`

**lib/json-extractor.mjs** — Safe JSON field extraction.

Create a single exported function `extractJsonField(rawJsonString, fieldName)` that:
1. Imports `appendJsonlEntry` from `./logger.mjs`
2. Uses a guard clause: if `rawJsonString` is not a string or is empty, log a warning via `appendJsonlEntry` with `{ level: 'warn', source: 'extractJsonField', message: 'Invalid JSON input: not a string or empty', field: fieldName }` and return `null`
3. Tries `JSON.parse(rawJsonString)` in a try/catch
4. On parse failure: log warning via `appendJsonlEntry` with `{ level: 'warn', source: 'extractJsonField', message: 'Failed to parse JSON', field: fieldName, error: parseError.message }` and return `null`
5. On success: check if `fieldName` exists as own property on the parsed object using `Object.hasOwn(parsedObject, fieldName)`
6. If field missing: log warning via `appendJsonlEntry` with `{ level: 'warn', source: 'extractJsonField', message: 'Field not found in JSON', field: fieldName }` and return `null`
7. If field exists: return `parsedObject[fieldName]`

Both modules: use `node:` prefix for all built-in imports. Self-explanatory naming, no abbreviations. Guard clauses, no nested if-if-if.
  </action>
  <verify>
Run `node --check lib/logger.mjs && node --check lib/json-extractor.mjs` — both pass syntax check.
Run `node -e "import('./lib/logger.mjs').then(m => { m.appendJsonlEntry({ test: true }); console.log('logger OK') })"` — prints "logger OK" and creates logs/lib-events.jsonl with one line.
Run `node -e "import('./lib/json-extractor.mjs').then(m => { console.log(m.extractJsonField('{\"a\":1}', 'a')); console.log(m.extractJsonField('{\"a\":1}', 'b')); console.log(m.extractJsonField('bad', 'x')) })"` — prints `1`, `null`, `null`.
  </verify>
  <done>
lib/logger.mjs exports appendJsonlEntry that atomically appends JSONL records. lib/json-extractor.mjs exports extractJsonField that safely extracts fields with null fallback and JSONL warning logging.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create retry utility and agent resolver</name>
  <files>lib/retry.mjs, lib/agent-resolver.mjs</files>
  <action>
**lib/retry.mjs** — Exponential backoff retry wrapper.

Create a single exported async function `retryWithBackoff(asyncFunction, options = {})` that:
1. Imports `appendJsonlEntry` from `./logger.mjs`
2. Accepts options: `{ maxAttempts = 10, initialDelayMilliseconds = 5000, operationLabel = 'operation', sessionName = null }`
3. Implements a loop from attempt 1 to maxAttempts:
   - Try calling `await asyncFunction()`
   - On success: return the result immediately
   - On failure: if this was the last attempt, throw the error
   - Otherwise: calculate delay as `initialDelayMilliseconds * Math.pow(2, attemptNumber - 1)` (5s, 10s, 20s, 40s...)
   - Log each retry attempt via `appendJsonlEntry({ level: 'warn', source: 'retryWithBackoff', message: \`Retry ${attemptNumber}/${maxAttempts} for ${operationLabel}\`, delay_ms: delayMilliseconds, error: caughtError.message }, sessionName)`
   - Wait using `await new Promise(resolve => setTimeout(resolve, delayMilliseconds))`
4. Use guard clause at top: if asyncFunction is not a function, throw TypeError immediately
5. Self-explanatory variable names: `attemptNumber`, `currentAttempt`, `delayMilliseconds`, `caughtError`

**lib/agent-resolver.mjs** — Session-to-agent lookup.

Create a single exported function `resolveAgentFromSession(tmuxSessionName)` that:
1. Imports `readFileSync`, `existsSync` from `node:fs`, `resolve`, `dirname` from `node:path`, `fileURLToPath` from `node:url`
2. Resolves SKILL_ROOT using `import.meta.url` + `dirname(dirname(fileURLToPath(import.meta.url)))` (two levels up from lib/)
3. Resolves `AGENT_REGISTRY_PATH` as `resolve(SKILL_ROOT, 'config', 'agent-registry.json')` — same pattern as launch-session.mjs
4. Guard clause: if `tmuxSessionName` is falsy (null, undefined, empty string), return `null` — silent skip per context decision
5. Guard clause: if agent-registry.json does not exist, return `null` — silent skip (not an error, the registry may not be configured yet)
6. Read and parse agent-registry.json. On parse error, return `null` (log warning via appendJsonlEntry with sessionName)
7. Guard clause: if `registry.agents` is not an array, return `null` (log warning)
8. Find agent where `agent.session_name === tmuxSessionName`
9. If no match found: return `null` — **no error, no log** (context decision: unrecognized sessions silently skip)
10. If match found but `agent.enabled === false`: return `null` — silent skip for disabled agents
11. If match found and enabled: return the full agent configuration object (let the handler decide what to do with it)

Both modules: `node:` prefix for all built-in imports. Self-explanatory naming, no abbreviations. Guard clauses throughout.
  </action>
  <verify>
Run `node --check lib/retry.mjs && node --check lib/agent-resolver.mjs` — both pass syntax check.
Run `node -e "import('./lib/retry.mjs').then(m => m.retryWithBackoff(() => 'ok', { maxAttempts: 1 }).then(r => console.log(r)))"` — prints "ok".
Run `node -e "import('./lib/retry.mjs').then(m => m.retryWithBackoff(() => { throw new Error('fail') }, { maxAttempts: 2, initialDelayMilliseconds: 100, operationLabel: 'test' }).catch(e => console.log('caught:', e.message)))"` — prints "caught: fail" after one retry.
Run `node -e "import('./lib/agent-resolver.mjs').then(m => { console.log(m.resolveAgentFromSession('nonexistent')); console.log(m.resolveAgentFromSession(null)) })"` — prints `null`, `null`.
  </verify>
  <done>
lib/retry.mjs exports retryWithBackoff that wraps async functions with configurable exponential backoff (5s base, 10 attempts default) and logs retry progress to JSONL. lib/agent-resolver.mjs exports resolveAgentFromSession that looks up agents by tmux session name in agent-registry.json, returns null silently for unrecognized/disabled sessions.
  </done>
</task>

</tasks>

<verification>
1. All four lib files pass `node --check`: `node --check lib/logger.mjs lib/json-extractor.mjs lib/retry.mjs lib/agent-resolver.mjs`
2. extractJsonField returns values for valid fields, null for missing/invalid
3. appendJsonlEntry creates JSONL files in logs/ without errors
4. retryWithBackoff retries failing functions with exponential backoff
5. resolveAgentFromSession returns null for unrecognized sessions, agent config for known sessions
6. No external dependencies added to package.json — only node: built-in modules used
7. Every function uses self-explanatory naming with no abbreviations
8. Guard clauses used throughout, no nested if-if-if blocks
</verification>

<success_criteria>
Four ESM modules exist in lib/ that are individually importable and pass syntax checks. extractJsonField safely handles invalid JSON. resolveAgentFromSession matches tmux sessions to agents. retryWithBackoff implements exponential backoff. appendJsonlEntry writes atomic JSONL entries. All use node: built-in modules only.
</success_criteria>

<output>
After completion, create `.planning/phases/02-shared-library/02-01-SUMMARY.md`
</output>
